# Transfer learning for music transcription

![Tensorflow](https://img.shields.io/badge/Tensorflow-%FFFFFF.svg?style=flat&logo=Tensorflow&logoColor=orange&color=white) [![License](https://img.shields.io/static/v1?label=License&message=MIT&color=blue)]() 

Code for the paper:<br />
  >**María Alfaro-Contreras**, Jose J. Valero-Mas, Jose M. Iñesta, Jorge Calvo-Zaragoza<br />
  *[Insights into transfer learning between image and audio music transcription](https://zenodo.org/record/6573248)*<br />
  19th Sound and Music Computing Conference, June 4th-12th 2022

Dataset used: **Camera-PrIMuS**. Available [here](https://grfia.dlsi.ua.es/primus/).
The partitions used can be found in the 5-crossval.zip file.

----

**Citation**

```bibtex
@inproceedings{alfaro2022insights,
  author       = {Alfaro-Contreras, Mar{\'i}a and Valero-Mas, Jose J. and I{\~n}esta, Jose M. and Calvo-Zaragoza, Jorge},
  title        = {{Insights into transfer learning between image and audio music transcription}},
  booktitle    = {{Proceedings of the 19th Sound and Music Computing Conference}},
  year         = 2022,
  pages        = {292--298},
  month        = jun,
  address      = {Saint-Étienne, France},
}
```

----

**Requirements**

tensorflow-gpu==2.3.1<br />
pandas==1.3.0<br />
numpy==1.18.5<br />
opencv-python==4.5.3.56
